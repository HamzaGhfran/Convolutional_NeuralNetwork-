{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b0f2aa",
   "metadata": {},
   "source": [
    "# ResNET CNN\n",
    "In papers describes as many layer stack in network Accuracy will increase which is not true. <br>\n",
    "As we increase layers in vanish gradient problem occure.<br>\n",
    "Gradient decent decrease exponentially as we backpropogate. <br>\n",
    "As we multiply many weight gradient reach toward Zero which cause early layers weight will change very small amount. <br>\n",
    "Here is example: gradient = w[l-1] * w[l-2] * w[l] ......... w[l] <br>\n",
    "if we multiply small numbers < 1 it create another small number.\n",
    "## ResNET\n",
    "ResNET solve this issue by adding \"skip connection\".\n",
    "Skip Connection create a small path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfce4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 22:41:18.867303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-20 22:41:19.978488: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-20 22:41:20.170059: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-20 22:41:21.738528: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-20 22:41:34.686044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hamza/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c553eb3",
   "metadata": {},
   "source": [
    "# Identity Block\n",
    "implementation of Identity Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab14518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training = True, initializer = random_uniform):\n",
    "    \"\"\"\n",
    "    X --> is input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f --> integer specifying middle conv layer window of main path.\n",
    "    filters --> python list of integers, defining the number of filters in Conv layer in main path.\n",
    "    training --> true: behaveing in training mode.\n",
    "                 False : behave not in training mode.\n",
    "    initializer--> set up initial weight of layer using random uniform.\n",
    "    \"\"\"\n",
    "    \n",
    "    F1, F2, F3 = filters \n",
    "    X_shortcut = X\n",
    "    cache = []\n",
    "    X = Conv2D(F1, kernel_size = 1, strides = (1, 1), padding = \"valid\", kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X =  Conv2D(F2, kernel_size = f, strides = (1, 1), padding = \"same\", kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Conv2D(F3, kernel_size = 1, strides = (1, 1), padding = \"valid\", kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    \n",
    "    X = Add()([X_shortcut, X])\n",
    "    \n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e7da13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mWith training=False\u001b[0m\n",
      "\n",
      "[[[  0.        0.        0.        0.     ]\n",
      "  [  0.        0.        0.        0.     ]]\n",
      "\n",
      " [[192.71236 192.71236 192.71236  96.85619]\n",
      "  [ 96.85619  96.85619  96.85619  48.9281 ]]\n",
      "\n",
      " [[578.1371  578.1371  578.1371  290.56854]\n",
      "  [290.56854 290.56854 290.56854 146.78427]]]\n",
      "96.85619\n",
      "\n",
      "\u001b[1mWith training=True\u001b[0m\n",
      "\n",
      "[[[0.      0.      0.      0.     ]\n",
      "  [0.      0.      0.      0.     ]]\n",
      "\n",
      " [[0.40739 0.40739 0.40739 0.40739]\n",
      "  [0.40739 0.40739 0.40739 0.40739]]\n",
      "\n",
      " [[4.99991 4.99991 4.99991 3.25948]\n",
      "  [3.25948 3.25948 3.25948 2.40739]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "A3 = identity_block(X, f=2, filters=[4, 4, 3], training = False, initializer=lambda seed=0:constant(value=1))\n",
    "print('\\033[1mWith training=False\\033[0m\\n')\n",
    "A3np = A3.numpy()\n",
    "print(np.around(A3.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))\n",
    "resume = A3np[:,(0,-1),:,:].mean(axis = 3)\n",
    "print(resume[1, 1, 0])\n",
    "\n",
    "print('\\n\\033[1mWith training=True\\033[0m\\n')\n",
    "np.random.seed(1)\n",
    "A4 = identity_block(X, f=2, filters=[3, 3, 3],\n",
    "                   initializer=lambda seed=0:constant(value=1),\n",
    "                   training=True)\n",
    "print(np.around(A4.numpy()[:,(0,-1),:,:].mean(axis = 3), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459413b8",
   "metadata": {},
   "source": [
    "# Convolve Layer\n",
    "In this layer we are going to implement convlove layer between shortcut path that helps to change input dimensions that are equal to main path dimension we called this block to Convolve block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3c14ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    X --> Input tensor dimensions (m, n_h_prev, n_w_prev, n_c_prev)\n",
    "    f --> size of kernal of used in layer\n",
    "    filters --> numbers of filter and kernal used in convlove layer\n",
    "    training --> if training is model going to train else for prediction\n",
    "    \"\"\"\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    X = Conv2D(F1, kernel_size = 1, strides = (s, s), padding = \"valid\", kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Conv2D(F2, kernel_size = f, strides = (1, 1), padding = \"same\", kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    X = Conv2D(F3, kernel_size = 1, strides = (1, 1), padding = \"valid\", kernel_initializer = initializer(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    \n",
    "    X_shortcut = Conv2D(F3, kernel_size = 1, strides = (s, s), padding = \"valid\", kernel_initializer = initializer(seed = 0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n",
    "    \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8d273a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.         0.66683817 0.         0.         0.888539   0.5274254 ]\n",
      "  [0.         0.65053666 0.         0.         0.8959285  0.49965227]]\n",
      "\n",
      " [[0.         0.6312079  0.         0.         0.86362475 0.47643146]\n",
      "  [0.         0.56883204 0.         0.         0.8553412  0.417093  ]]], shape=(2, 2, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "#X = np.random.randn(3, 4, 4, 6).astype(np.float32)\n",
    "X1 = np.ones((1, 4, 4, 3)) * -1\n",
    "X2 = np.ones((1, 4, 4, 3)) * 1\n",
    "X3 = np.ones((1, 4, 4, 3)) * 3\n",
    "\n",
    "X = np.concatenate((X1, X2, X3), axis = 0).astype(np.float32)\n",
    "A = convolve_block(X, f = 2, filters = [2, 4, 6], training=False)\n",
    "\n",
    "assert type(A) == EagerTensor, \"Use only tensorflow and keras functions\"\n",
    "assert tuple(tf.shape(A).numpy()) == (3, 2, 2, 6), \"Wrong shape.\"\n",
    "print(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_50(input_shape = (64, 64, 3), classes = 6):\n",
    "    x_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding3D((3, 3))(x_input)\n",
    "    X = Conv2D(64, kernel_size = 7, strides = (2, 2), name = \"conv1\", kernel_initializer = glorot_uniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = \"bnconv1\")(X)\n",
    "    X MaxPooling2D((3, 3), strides = (2, 2))(X)\n",
    "    \n",
    "    X = convolve_block(X, f = 3, [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
